# /usr/bin/python3
'''''
GB_PID_pump.py

GB_PIDæ§åˆ¶å™¨ï¼Œåˆ©ç”¨Guaranteed Bounded PIDæ§åˆ¶æ³µè½‰é€Ÿ

æœ¬ç ”ç©¶ä¸­çš„æ™¶ç‰‡ç“¦æ•¸å°æ‡‰çš„é›»æºä¾›æ‡‰å™¨åƒæ•¸è¨­ç½®å¦‚ä¸‹
1KWï¼š220V_8A
1.5KWï¼š285V_8A
1.9KWï¼š332V_8A

å°æ‡‰çš„é¢¨æ‰‡èˆ‡æ³µæœ€ä½è½‰é€Ÿå¦‚ä¸‹
æ³µï¼š40% duty cycle
é¢¨æ‰‡ï¼š30% duty cycle
'''''
import time
import sys
# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append('/home/inventec/Desktop/2KWCDU_ä¿®æ”¹ç‰ˆæœ¬')
sys.path.append('/home/inventec/Desktop/2KWCDU_ä¿®æ”¹ç‰ˆæœ¬/code_manage/Control_Unit')
sys.path.append('/home/inventec/Desktop/2KWCDU_ä¿®æ”¹ç‰ˆæœ¬/code_manage/Controllers/MPC/Model_constructor')
sys.path.append('/home/inventec/Desktop/2KWCDU_ä¿®æ”¹ç‰ˆæœ¬/code_manage/Controllers/MPC')
import ADAMScontroller
import pwmcontroller as ctrl
import multi_channel_pwmcontroller as multi_ctrl
from simple_pid import PID
import matplotlib.pyplot as plt
import numpy as np
import time
import joblib
# ä¿®æ­£æ¨¡å‹å°å…¥è·¯å¾‘ - èˆ‡ SA_iTransformer.py ä¿æŒä¸€è‡´
from code_manage.Controllers.MPC.model import Model
import torch
import torch.nn as nn
from collections import deque
import math
from sklearn.preprocessing import MinMaxScaler
import os
import pandas as pd
import csv
import random
import Model_tester as mt
import Sequence_Window_Processor
from tabulate import tabulate

class ModelConfig:
    """
    æ¨¡å‹é…ç½®é¡ï¼Œçµ±ä¸€ç®¡ç†æ¨¡å‹åƒæ•¸
    """
    def __init__(self, input_dim=7, d_model=16, n_heads=8, e_layers=1, d_ff=16, 
                 dropout=0.01, seq_len=40, pred_len=8, embed='timeF', freq='h',
                 class_strategy='cls', activation='gelu', output_attention=False, use_norm=True):
        """
        åˆå§‹åŒ–æ¨¡å‹é…ç½®
        
        Args:
            input_dim (int): è¼¸å…¥ç‰¹å¾µç¶­åº¦
            d_model (int): æ¨¡å‹éš±è—å±¤ç¶­åº¦
            n_heads (int): æ³¨æ„åŠ›é ­æ•¸
            e_layers (int): ç·¨ç¢¼å™¨å±¤æ•¸
            d_ff (int): å‰é¥‹ç¶²çµ¡ç¶­åº¦
            dropout (float): Dropoutæ¯”ç‡
            seq_len (int): è¼¸å…¥åºåˆ—é•·åº¦
            pred_len (int): é æ¸¬åºåˆ—é•·åº¦
            embed (str): åµŒå…¥é¡å‹
            freq (str): æ™‚é–“é »ç‡
            class_strategy (str): åˆ†é¡ç­–ç•¥
            activation (str): æ¿€æ´»å‡½æ•¸
            output_attention (bool): æ˜¯å¦è¼¸å‡ºæ³¨æ„åŠ›æ¬Šé‡
            use_norm (bool): æ˜¯å¦ä½¿ç”¨å±¤æ­¸ä¸€åŒ–
        """
        self.input_dim = input_dim
        self.d_model = d_model
        self.n_heads = n_heads
        self.e_layers = e_layers
        self.d_ff = d_ff
        self.dropout = dropout
        self.seq_len = seq_len
        self.pred_len = pred_len
        self.embed = embed
        self.freq = freq
        self.class_strategy = class_strategy
        self.activation = activation
        self.output_attention = output_attention
        self.use_norm = use_norm

adam_port = '/dev/ttyUSB0'
fan1_port = '/dev/ttyAMA4'
fan2_port = '/dev/ttyAMA5'
pump_port = '/dev/ttyAMA3'
#é¸æ“‡æ¨¡å‹
test_model='iTransformer_no_air_out_seq25_pred8_dmodel16_dff32_nheads2_elayers1_dropout0.01_lr0.0001_batchsize512_epochs140'

# æ›´æ–°æ™‚é–“çª—å£å¤§å°
time_window = 25

#è¨­ç½®å¯¦é©—è³‡æ–™æ”¾ç½®çš„è³‡æ–™å¤¾
exp_name = f'/home/inventec/Desktop/2KWCDU_ä¿®æ”¹ç‰ˆæœ¬/data_manage/Real_time_Prediction_data/iTransformer/{test_model}'
#è¨­ç½®å¯¦é©—è³‡æ–™æª”æ¡ˆåç¨±
exp_var = 'all_random_test'
#è¨­ç½®å¯¦é©—è³‡æ–™æ¨™é¡Œ
custom_headers = ['time', 'T_GPU', 'T_heater', 'T_CDU_in', 'T_CDU_out', 'T_env', 'T_air_in', 'T_air_out', 'TMP8', 'fan_duty', 'pump_duty', 'GPU_Watt(KW)']

adam = ADAMScontroller.DataAcquisition(exp_name=exp_name, exp_var=exp_var, port=adam_port, csv_headers=custom_headers)
fan1 = multi_ctrl.multichannel_PWMController(fan1_port)
fan2 = multi_ctrl.multichannel_PWMController(fan2_port)
pump = ctrl.XYKPWMController(pump_port)
print('æ¨¡å‹åˆå§‹åŒ–.....')


# ä¿®æ”¹æ¨¡å‹å’Œscalerè·¯å¾‘
model_path = f'/home/inventec/Desktop/2KWCDU_ä¿®æ”¹ç‰ˆæœ¬/code_manage/Predict_Model/iTransformer/iTransformer_no_air_out_seq25_pred8_dmodel16_dff32_nheads2_elayers1_dropout0.01_lr0.0001_batchsize512_epochs140/best_model.pth'
# è¨­å®šMinMaxScalerçš„è·¯å¾‘ï¼Œæ­¤scalerç”¨æ–¼å°‡è¼¸å…¥æ•¸æ“šæ­¸ä¸€åŒ–åˆ°[0,1]å€é–“
# è©²scaleræ˜¯åœ¨è¨“ç·´æ¨¡å‹æ™‚ä¿å­˜çš„ï¼Œç¢ºä¿é æ¸¬æ™‚ä½¿ç”¨ç›¸åŒçš„æ•¸æ“šç¸®æ”¾æ–¹å¼
scaler_path = f'/home/inventec/Desktop/2KWCDU_ä¿®æ”¹ç‰ˆæœ¬/code_manage/Predict_Model/iTransformer/iTransformer_no_air_out_seq25_pred8_dmodel16_dff32_nheads2_elayers1_dropout0.01_lr0.0001_batchsize512_epochs140/scalers.jlib' 
# æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨,å¦‚æœä¸å­˜åœ¨å‰‡å‰µå»ºä¸¦å¯«å…¥æ¨™é¡Œè¡Œ
prediction_file = f'/home/inventec/Desktop/2KWCDU_ä¿®æ”¹ç‰ˆæœ¬/data_manage/Real_time_Prediction/iTransformer/iTransformer_no_air_out_seq25_pred8_dmodel16_dff32_nheads2_elayers1_dropout0.01_lr0.0001_batchsize512_epochs140/Model_test_{exp_var}.csv'
if not os.path.exists(prediction_file):
    os.makedirs(os.path.dirname(prediction_file), exist_ok=True)
    with open(prediction_file, 'w') as f:
        f.write('timestamp,actual_temp(CDU_out),actual_temp(GPU),fan_duty,pump_duty,pred_1,pred_2,pred_3,pred_4,pred_5,pred_6,pred_7,pred_8\n')

# è¨­ç½®åˆå§‹è½‰é€Ÿ
pump_duty=60
pump.set_duty_cycle(pump_duty)
fan_duty=60
fan1.set_all_duty_cycle(fan_duty)
fan2.set_all_duty_cycle(fan_duty)

# è¨­ç½®ADAMæ§åˆ¶å™¨
adam.start_adam()
adam.update_duty_cycles(fan_duty, pump_duty)
time.sleep(1)

# åŠ è¼‰æ¨¡å‹å’Œscaler
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ä½¿ç”¨çµ±ä¸€çš„æ¨¡å‹é…ç½®
model_config = ModelConfig(
    input_dim=6,
    d_model=16,
    n_heads=2,
    e_layers=1,
    d_ff=32,
    dropout=0.01,
    seq_len=25,
    pred_len=8
)

# å‰µå»ºæ¨¡å‹å¯¦ä¾‹ - ä¿®æ­£åˆå§‹åŒ–æ–¹å¼
model = Model(
    model_config
).to(device)

# è¼‰å…¥æ¨¡å‹æ¬Šé‡ - ä¿®æ­£åŠ è¼‰æ–¹å¼
checkpoint = torch.load(model_path, map_location=device)
if 'model_state_dict' in checkpoint:
    # æª¢æŸ¥é»åŒ…å«æ¨¡å‹ç‹€æ…‹å­—å…¸
    model.load_state_dict(checkpoint['model_state_dict'])
else:
    # ç›´æ¥å˜—è©¦åŠ è¼‰
    model.load_state_dict(checkpoint)

# è¨­ç½®ç‚ºè©•ä¼°æ¨¡å¼
model.eval()

seq_window_processor = Sequence_Window_Processor.SequenceWindowProcessor(
    window_size=time_window,
    adams_controller=adam,  # ä½ çš„ ADAMScontroller ç‰©ä»¶
    scaler_path=scaler_path,  # ä½ çš„ Scaler æª”æ¡ˆ
    device="cpu"
)



# ä¿®æ”¹é æ¸¬æ•¸æ“šè¨˜éŒ„çµæ§‹
prediction_data = {
    'timestamp': [],
    'actual_temps(CDU_out)': [],
    'actual_temps(GPU)': [],
    'T_env': [],
    'fan_duty': [],
    'pump_duty': [],
    'predicted_sequence': []  # å„²å­˜8å€‹æ™‚é–“æ­¥çš„é æ¸¬
}

# å‰µå»º Model_tester ç‰©ä»¶
model_tester = mt.Model_tester(fan1=fan1, fan2=fan2, pump=pump, adam=adam)

# é¸æ“‡æ¸¬è©¦æ¨¡å¼ (1: åªè®Šå‹•é¢¨æ‰‡, 2: åªè®Šå‹•æ³µ, 3: éš¨æ©Ÿè®Šå‹•)
model_tester.start_test(3,900)  # é€™è£¡é¸æ“‡éš¨æ©Ÿè®Šå‹•æ¸¬è©¦


while model_tester.phase != "end":
    try:
        model_tester.update_test()

        # âœ… ç¢ºä¿ window_data å·²æº–å‚™å¥½
        input_tensor = seq_window_processor.get_window_data(normalize=False)

        if input_tensor is None:  # ä¿®æ­£æ¢ä»¶ï¼Œæ‡‰è©²ç­‰å¾…æ•¸æ“šæº–å‚™å¥½
            time.sleep(1)
            continue

        # ç²å–ç•¶å‰æ•¸æ“š
        data = [
            adam.buffer[0],  # T_GPU
            adam.buffer[2],  # T_CDU_in
            adam.buffer[3],  # T_CDU_out
            adam.buffer[4],  # T_env
            adam.buffer[5],  # T_air_in
            adam.buffer[6],  # T_air_out
            adam.buffer[8],  # fan_duty
            adam.buffer[9]   # pump_duty
        ]

        # åŸ·è¡Œé æ¸¬
        if input_tensor is not None:
            # è¨˜éŒ„æ¨è«–é–‹å§‹æ™‚é–“
            inference_start = time.time()
            
            with torch.no_grad():
                # æª¢æŸ¥æ¨¡å‹è¼¸å‡º
                model_output = model(seq_window_processor.transform_input_data(input_tensor))
                scaled_predictions = model_output[0].cpu().numpy()  # ç²å–ç¸®æ”¾å¾Œçš„é æ¸¬çµæœ
                # ä½¿ç”¨ä¿®æ”¹å¾Œçš„åè½‰ç¸®æ”¾æ–¹æ³•
                predicted_temps = seq_window_processor.inverse_transform_predictions(scaled_predictions)  # åè½‰ç¸®æ”¾
                
                # ä½¿ç”¨ä¿®æ”¹å¾Œçš„åè½‰ç¸®æ”¾æ–¹æ³•
                predicted_sequence = seq_window_processor.inverse_transform_predictions(scaled_predictions)  # åè½‰ç¸®æ”¾
            
            # è¨ˆç®—æ¨è«–æ™‚é–“
            inference_duration = time.time() - inference_start
        else:
            predicted_sequence = None
            inference_duration = 0.0

        # è¨˜éŒ„çµæœ
        current_time = time.time()
        
        # åªåœ¨æœ‰æœ‰æ•ˆé æ¸¬çµæœæ™‚æ‰è¨˜éŒ„å’Œè™•ç†æ•¸æ“š
        if predicted_sequence is not None:
            keys = ['timestamp', 'actual_temps(CDU_out)', 'actual_temps(GPU)', 'T_env', 'fan_duty', 'pump_duty', 'predicted_sequence']
            values = [current_time, adam.buffer[3], adam.buffer[0], adam.buffer[4], adam.buffer[8], adam.buffer[9], predicted_sequence]
            for key, value in zip(keys, values):
                prediction_data[key].append(value)

            # å¯«å…¥é æ¸¬æ•¸æ“šåˆ° CSV æª”æ¡ˆ
            with open(prediction_file, 'a', newline='') as f:
                writer = csv.writer(f)
                timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(current_time))
                row = [timestamp, adam.buffer[3], data[0], adam.buffer[8], adam.buffer[9]] + [f'{temp:.2f}' for temp in predicted_sequence]
                writer.writerow(row)

            # ç³»çµ±ç‹€æ…‹æ•¸æ“š
            system_status_data = [
                ["ğŸŒ¡ï¸ ç•¶å‰å‡ºå£æº«åº¦", f"{adam.buffer[3]:.2f}Â°C"],
                ["ğŸ’» ç•¶å‰æ™¶ç‰‡æº«åº¦", f"{data[0]:.2f}Â°C"],
                ["ğŸŒ ç•¶å‰ç’°å¢ƒæº«åº¦", f"{data[3]:.2f}Â°C"],
                ["ğŸ’¨ ç•¶å‰é€²é¢¨æº«åº¦", f"{data[4]:.2f}Â°C"],
                ["ğŸŒ¬ï¸ ç•¶å‰å‡ºé¢¨æº«åº¦", f"{data[5]:.2f}Â°C"],
                ["ğŸ”„ ç•¶å‰é¢¨æ‰‡è½‰é€Ÿ", f"{data[6]:.2f}%"],
                ["ğŸ’§ ç•¶å‰æ³µè½‰é€Ÿ", f"{data[7]:.2f}%"]
            ]

            # é æ¸¬çµæœæ•¸æ“š
            prediction_results_data = [
                ["ğŸ”® æœªä¾†8æ­¥é æ¸¬æº«åº¦", predicted_sequence.tolist()],  # ä¿®æ­£ç‚ºåˆ—è¡¨ï¼Œä»¥ç¢ºä¿å¯è®€æ€§
                ["ğŸ“ scaled_predictions å½¢ç‹€", scaled_predictions.shape],
                ["â±ï¸ æ¨¡å‹æ¨è«–æ™‚é–“", f"{inference_duration:.4f} ç§’"]
            ]

            # æ‰“å°ç³»çµ±ç‹€æ…‹è¡¨æ ¼
            print("ğŸŒŸ==================== ç³»çµ±ç‹€æ…‹ ====================ğŸŒŸ")
            print(tabulate(system_status_data, tablefmt="grid"))

            # æ‰“å°é æ¸¬çµæœè¡¨æ ¼
            print("\nğŸŒŸ==================== é æ¸¬çµæœ ====================ğŸŒŸ")
            print(tabulate(prediction_results_data, tablefmt="grid"))
        else:
            print("âš ï¸ ç­‰å¾…æ•¸æ“šæº–å‚™ä¸­...")
        
        time.sleep(1)

    except ValueError as e:
        print(f"âš ï¸ éŒ¯èª¤: {str(e)}")
        time.sleep(1)

    except KeyboardInterrupt:
        print("å¯¦é©—çµæŸï¼Œç¨‹åºå·²å®‰å…¨é€€å‡ºã€‚")
        adam.stop_adam()
        
        break

    except Exception as e:
        print(f"âŒ é æ¸¬éŒ¯èª¤: {str(e)}")
        time.sleep(1)
adam.stop_adam()
fan1.set_all_duty_cycle(60)
fan2.set_all_duty_cycle(60)
pump.set_duty_cycle(60)
print("ğŸ”´ å¯¦é©—çµæŸï¼Œç¨‹åºå·²å®‰å…¨é€€å‡ºã€‚")


adam.stop_adam()
fan1.set_all_duty_cycle(60)
fan2.set_all_duty_cycle(60)
pump.set_duty_cycle(60)






