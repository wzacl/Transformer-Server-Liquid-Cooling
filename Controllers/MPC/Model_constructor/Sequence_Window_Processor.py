import threading
import time
import numpy as np
import joblib
import torch

class SequenceWindowProcessor:
    """
    åºåˆ—çª—å£è™•ç†å™¨ï¼Œç”¨æ–¼ç®¡ç†æ™‚é–“åºåˆ—æ•¸æ“šçš„æ»‘å‹•çª—å£ï¼Œè™•ç†æ•¸æ“šæ¨™æº–åŒ–å’Œåæ¨™æº–åŒ–ï¼Œ
    ä»¥åŠç›£è½ADAMæ§åˆ¶å™¨çš„æ•¸æ“šæ›´æ–°ã€‚
    
    è©²é¡è² è²¬ç¶­è­·ä¸€å€‹å›ºå®šå¤§å°çš„æ•¸æ“šç·©è¡å€ï¼Œç”¨æ–¼å­˜å„²æœ€è¿‘çš„ç³»çµ±ç‹€æ…‹æ•¸æ“šï¼Œ
    ä¸¦æä¾›æ•¸æ“šé è™•ç†å’Œå¾Œè™•ç†åŠŸèƒ½ï¼Œç‚ºé æ¸¬æ¨¡å‹å’ŒMPCæ§åˆ¶å™¨æä¾›æ‰€éœ€çš„è¼¸å…¥ã€‚
    """
    def __init__(self, window_size=35, adams_controller=None, scaler_path=None, device="cpu"):
        """
        åˆå§‹åŒ–åºåˆ—çª—å£è™•ç†å™¨
        
        Args:
            window_size (int): æ»‘å‹•çª—å£å¤§å°ï¼Œé»˜èªç‚º35
            adams_controller: ADAMæ§åˆ¶å™¨å¯¦ä¾‹ï¼Œç”¨æ–¼ç²å–å¯¦æ™‚æ•¸æ“š
            scaler_path (str): æ•¸æ“šæ¨™æº–åŒ–å™¨çš„ä¿å­˜è·¯å¾‘
            device (str): è¨ˆç®—è¨­å‚™ï¼Œ'cpu'æˆ–'cuda'
        """
        self.window_size = window_size
        self.adam = adams_controller
        self.device = device
        self.buffer = np.zeros((window_size, 6))  # ç›´æ¥å„²å­˜åŸå§‹æ•¸æ“š
        self.buffer_lock = threading.Lock()

        # åŠ è¼‰ Data Processor (Scaler)
        self.scaler = joblib.load(scaler_path)
        if isinstance(self.scaler, tuple) and len(self.scaler) == 2:
            self.input_scaler, self.output_scaler = self.scaler
        else:
            raise ValueError("è¼‰å…¥çš„ scaler æ‡‰ç‚º (input_scaler, output_scaler) æ ¼å¼ï¼Œä½†ç²å¾—å–®ä¸€ scalerã€‚")

        self.data_count = 0
        self.adam.data_updated_event.clear()  # æ¸…é™¤åˆå§‹äº‹ä»¶
        self.start_adam_listener()
        

        # ç”¨æ–¼æº«åº¦è®ŠåŒ–è¶¨å‹¢è¿½è¹¤
        self.temp_trend = None  # None: æœªçŸ¥, 1: ä¸Šå‡, -1: ä¸‹é™, 0: ç©©å®š
        

    def start_adam_listener(self):
        """
        å•Ÿå‹•ç›£è½ ADAM æ›´æ–°äº‹ä»¶çš„åŸ·è¡Œç·’
        
        å‰µå»ºä¸¦å•Ÿå‹•ä¸€å€‹å®ˆè­·ç·šç¨‹ï¼Œç”¨æ–¼ç›£è½ADAMæ§åˆ¶å™¨çš„æ•¸æ“šæ›´æ–°äº‹ä»¶ï¼Œ
        ç•¶æœ‰æ–°æ•¸æ“šæ™‚è‡ªå‹•æ›´æ–°å…§éƒ¨ç·©è¡å€ã€‚
        """
        thread = threading.Thread(target=self.adam_update_listener, daemon=True)
        thread.start()

    def adam_update_listener(self):
        """
        ç›£è½ ADAM æ›´æ–°äº‹ä»¶ï¼Œè‡ªå‹•æ›´æ–° buffer
        
        æ­¤æ–¹æ³•åœ¨ç¨ç«‹ç·šç¨‹ä¸­é‹è¡Œï¼ŒæŒçºŒç›£è½ADAMæ§åˆ¶å™¨çš„æ•¸æ“šæ›´æ–°äº‹ä»¶ï¼Œ
        ç•¶äº‹ä»¶è¢«è§¸ç™¼æ™‚ï¼Œèª¿ç”¨update_from_adamæ–¹æ³•æ›´æ–°æ•¸æ“šç·©è¡å€ã€‚
        """
        while True:
            self.adam.data_updated_event.wait()  # ç­‰å¾… ADAM è§¸ç™¼äº‹ä»¶
            self.update_from_adam()
            self.adam.data_updated_event.clear()  # æ¸…é™¤äº‹ä»¶

    def update_from_adam(self):
        """
        ç•¶ ADAMScontroller è§¸ç™¼æ›´æ–°æ™‚ï¼Œç›´æ¥æ›´æ–° buffer å…§çš„æ•¸æ“š
        
        å¾ADAMæ§åˆ¶å™¨ç²å–æœ€æ–°çš„ç³»çµ±ç‹€æ…‹æ•¸æ“šï¼ŒåŒ…æ‹¬æº«åº¦å’Œæ§åˆ¶ä¿¡è™Ÿï¼Œ
        ä¸¦å°‡å…¶æ·»åŠ åˆ°æ»‘å‹•çª—å£ç·©è¡å€ä¸­ï¼ŒåŒæ™‚æ›´æ–°æ•¸æ“šè¨ˆæ•¸å™¨ã€‚
        """
        with self.buffer_lock:
            # ç‰¹å¾µé †åºç‚º: T_GPU, T_CDU_in, T_CDU_out, T_air_in, T_air_out, fan_duty, pump_duty
            # èˆ‡è¨“ç·´æ¨¡å‹æ™‚ä½¿ç”¨çš„ç‰¹å¾µé †åºä¸€è‡´
            raw_data = np.array([
                self.adam.buffer[0],  # T_GPU
                self.adam.buffer[2],  # T_CDU_in
                self.adam.buffer[3],  # T_CDU_out
                self.adam.buffer[5],  # T_air_in
                self.adam.buffer[8],  # fan_duty
                self.adam.buffer[9]   # pump_duty
            ]).reshape(1, -1)
            
            self.buffer = np.roll(self.buffer, -1, axis=0)
            self.buffer[-1, :] = raw_data  # æ›´æ–° buffer
            self.data_count += 1

    def get_window_data(self, normalize=False):
        """
        å–å¾—æ™‚é–“çª—å£æ•¸æ“š
        
        ç²å–ç•¶å‰æ»‘å‹•çª—å£ä¸­çš„æ‰€æœ‰æ•¸æ“šï¼Œå¯é¸æ˜¯å¦é€²è¡Œæ¨™æº–åŒ–è™•ç†ã€‚
        
        Args:
            normalize (bool): è‹¥ç‚º Trueï¼Œå‰‡å›å‚³æ­£è¦åŒ–å¾Œçš„æ•¸æ“š
            
        Returns:
            numpy.ndarray æˆ– torch.Tensor: çª—å£æ•¸æ“šï¼Œå¦‚æœæ•¸æ“šä¸è¶³å‰‡è¿”å›None
            å¦‚æœnormalize=Trueï¼Œè¿”å›æ¨™æº–åŒ–å¾Œçš„å¼µé‡ï¼›å¦å‰‡è¿”å›åŸå§‹numpyæ•¸çµ„
        """
        with self.buffer_lock:
            if self.data_count < self.window_size:
                print(f"â³ ç•¶å‰è³‡æ–™å®¤çª—å…§è³‡æ–™é‡ {self.data_count}/{self.window_size}ï¼Œè«‹ç¨ç­‰...")
                return None
            else:
                print(f"âœ… è³‡æ–™å®¤çª—å…§è³‡æ–™é‡å……è¶³ï¼Œå°‡é–‹å§‹é€²è¡Œé æ¸¬èˆ‡æœ€ä½³åŒ–")
            
            data = self.buffer.copy()
            
            if normalize and hasattr(self.input_scaler, "transform"):
                data = torch.tensor(self.input_scaler.transform(data), dtype=torch.float32).unsqueeze(0).to(self.device)
            return data

    def inverse_transform_predictions(self, scaled_predictions, smooth=True):
        """
        åæ¨™æº–åŒ–é æ¸¬æ•¸æ“š
        
        å°‡æ¨¡å‹è¼¸å‡ºçš„æ¨™æº–åŒ–é æ¸¬çµæœè½‰æ›å›åŸå§‹å°ºåº¦ã€‚
        
        Args:
            scaled_predictions (numpy.ndarray): æ¨™æº–åŒ–å¾Œçš„é æ¸¬æ•¸æ“š
            smooth (bool): æ˜¯å¦å°é æ¸¬çµæœé€²è¡Œå¹³æ»‘è™•ç†
            
        Returns:
            numpy.ndarray: åæ¨™æº–åŒ–å¾Œçš„é æ¸¬æ•¸æ“š
            
        Raises:
            AttributeError: å¦‚æœoutput_scalerç¼ºå°‘inverse_transformæ–¹æ³•
        """
        #print(f"ğŸ”¢ æ¨™æº–åŒ–é æ¸¬çµæœå½¢ç‹€: {scaled_predictions.shape}")
        
        if hasattr(self.output_scaler, "inverse_transform"):
            # iTransformeræ¨¡å‹è¼¸å‡ºçš„å½¢ç‹€è™•ç†
            if len(scaled_predictions.shape) == 2:  # å¦‚æœæ˜¯2DçŸ©é™£ [seq_len, features]
                # åªå–CDUå‡ºæ°´æº«åº¦é æ¸¬ï¼ˆç¬¬3åˆ—ï¼Œå°æ‡‰ç´¢å¼•2ï¼‰
                
                cdu_out_predictions = scaled_predictions[:, 2] if scaled_predictions.shape[1] >= 3 else scaled_predictions[:, 0]
                
                # ç¢ºä¿åªå–å‰pred_lenå€‹æ™‚é–“æ­¥(8å€‹)
                cdu_out_predictions = cdu_out_predictions[:8]
                
                # æ“´å±•ç‚ºæ­£ç¢ºçš„å½¢ç‹€ä»¥é€²è¡Œåæ¨™æº–åŒ–
                scaled_reshape = cdu_out_predictions.reshape(-1, 1)
            else:
                # å¦‚æœæ˜¯å…¶ä»–å½¢ç‹€ï¼Œå˜—è©¦åˆç†è™•ç†
                # å…ˆæ‰“å¹³ç„¶å¾Œå–å‰8å€‹å€¼
                cdu_out_predictions = scaled_predictions.flatten()[:8]
                scaled_reshape = cdu_out_predictions.reshape(-1, 1)
            
            #print(f"ğŸ”„ è™•ç†å¾Œå½¢ç‹€: {scaled_reshape.shape}")
            
            # åæ¨™æº–åŒ–
            inverse_data = self.output_scaler.inverse_transform(scaled_reshape)[:, 0]
            #print(f"ğŸ“Š åæ¨™æº–åŒ–çµæœ(åªé¡¯ç¤ºCDUå‡ºæ°´æº«åº¦çš„é æ¸¬): {[f'{temp:.2f}' for temp in inverse_data]}")
            
            return inverse_data
        else:
            raise AttributeError("output_scaler ç¼ºå°‘ inverse_transform æ–¹æ³•ï¼Œè«‹æª¢æŸ¥ scaler æ˜¯å¦æ­£ç¢ºè¼‰å…¥ã€‚")

    def transform_input_data(self, data):
        """
        æ¨™æº–åŒ–è¼¸å…¥æ•¸æ“š
        
        å°‡åŸå§‹è¼¸å…¥æ•¸æ“šè½‰æ›ç‚ºæ¨™æº–åŒ–æ ¼å¼ï¼Œä»¥ä¾¿æ¨¡å‹è™•ç†ã€‚
        
        Args:
            data (numpy.ndarray): åŸå§‹è¼¸å…¥æ•¸æ“š
            
        Returns:
            torch.Tensor: æ¨™æº–åŒ–å¾Œçš„æ•¸æ“šå¼µé‡ï¼Œå·²èª¿æ•´ç‚ºæ¨¡å‹æ‰€éœ€çš„ç¶­åº¦å’Œè¨­å‚™
            
        Raises:
            AttributeError: å¦‚æœinput_scalerç¼ºå°‘transformæ–¹æ³•
        """
        if hasattr(self.input_scaler, "transform"):
            # æŸ¥çœ‹æœ€å¾Œä¸€è¡Œè³‡æ–™çš„è½‰é€Ÿå€¼
            #print(f"âš™ï¸ è¼¸å…¥æ•¸æ“šæœ€å¾Œä¸€è¡Œ: {[f'{val:.2f}' for val in data[-1]]}")
            #print(f"ğŸ“Š è¼¸å…¥ç‰¹å¾µé †åº: T_GPU, T_CDU_in, T_CDU_out, T_air_in, T_air_out, fan_duty, pump_duty")
            
            # æ¨™æº–åŒ–æ•¸æ“š
            scaled_data = self.input_scaler.transform(data)
            #print(f"ğŸ”¢ æ¨™æº–åŒ–å¾Œæœ€å¾Œä¸€è¡Œ: {[f'{val:.4f}' for val in scaled_data[-1]]}")
            
            # è½‰æ›ç‚ºå¼µé‡
            return torch.tensor(scaled_data, dtype=torch.float32).unsqueeze(0).to(self.device)
        else:
            raise AttributeError("input_scaler ç¼ºå°‘ transform æ–¹æ³•ï¼Œè«‹æª¢æŸ¥ scaler æ˜¯å¦æ­£ç¢ºè¼‰å…¥ã€‚")
    
