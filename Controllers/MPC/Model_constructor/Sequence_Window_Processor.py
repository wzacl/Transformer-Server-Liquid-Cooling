import threading
import time
import numpy as np
import joblib
import torch

class SequenceWindowProcessor:
    """
    åºåˆ—çª—å£è™•ç†å™¨ï¼Œç”¨æ–¼ç®¡ç†æ™‚é–“åºåˆ—æ•¸æ“šçš„æ»‘å‹•çª—å£ï¼Œè™•ç†æ•¸æ“šæ¨™æº–åŒ–å’Œåæ¨™æº–åŒ–ï¼Œ
    ä»¥åŠç›£è½ADAMæ§åˆ¶å™¨çš„æ•¸æ“šæ›´æ–°ã€‚
    
    è©²é¡è² è²¬ç¶­è­·ä¸€å€‹å›ºå®šå¤§å°çš„æ•¸æ“šç·©è¡å€ï¼Œç”¨æ–¼å­˜å„²æœ€è¿‘çš„ç³»çµ±ç‹€æ…‹æ•¸æ“šï¼Œ
    ä¸¦æä¾›æ•¸æ“šé è™•ç†å’Œå¾Œè™•ç†åŠŸèƒ½ï¼Œç‚ºé æ¸¬æ¨¡å‹å’ŒMPCæ§åˆ¶å™¨æä¾›æ‰€éœ€çš„è¼¸å…¥ã€‚
    """
    def __init__(self, window_size=35, adams_controller=None, scaler_path=None, device="cpu"):
        """
        åˆå§‹åŒ–åºåˆ—çª—å£è™•ç†å™¨
        
        Args:
            window_size (int): æ»‘å‹•çª—å£å¤§å°ï¼Œé»˜èªç‚º35
            adams_controller: ADAMæ§åˆ¶å™¨å¯¦ä¾‹ï¼Œç”¨æ–¼ç²å–å¯¦æ™‚æ•¸æ“š
            scaler_path (str): æ•¸æ“šæ¨™æº–åŒ–å™¨çš„ä¿å­˜è·¯å¾‘
            device (str): è¨ˆç®—è¨­å‚™ï¼Œ'cpu'æˆ–'cuda'
        """
        self.window_size = window_size
        self.adam = adams_controller
        self.device = device
        self.buffer = np.zeros((window_size, 7))  # ç›´æ¥å„²å­˜åŸå§‹æ•¸æ“š
        self.buffer_lock = threading.Lock()

        # åŠ è¼‰ Data Processor (Scaler)
        self.scaler = joblib.load(scaler_path)
        if isinstance(self.scaler, tuple) and len(self.scaler) == 2:
            self.input_scaler, self.output_scaler = self.scaler
        else:
            raise ValueError("è¼‰å…¥çš„ scaler æ‡‰ç‚º (input_scaler, output_scaler) æ ¼å¼ï¼Œä½†ç²å¾—å–®ä¸€ scalerã€‚")

        self.data_count = 0
        self.adam.data_updated_event.clear()  # æ¸…é™¤åˆå§‹äº‹ä»¶
        self.start_adam_listener()
        

        # ç”¨æ–¼æº«åº¦è®ŠåŒ–è¶¨å‹¢è¿½è¹¤
        self.temp_trend = None  # None: æœªçŸ¥, 1: ä¸Šå‡, -1: ä¸‹é™, 0: ç©©å®š
        

    def start_adam_listener(self):
        """
        å•Ÿå‹•ç›£è½ ADAM æ›´æ–°äº‹ä»¶çš„åŸ·è¡Œç·’
        
        å‰µå»ºä¸¦å•Ÿå‹•ä¸€å€‹å®ˆè­·ç·šç¨‹ï¼Œç”¨æ–¼ç›£è½ADAMæ§åˆ¶å™¨çš„æ•¸æ“šæ›´æ–°äº‹ä»¶ï¼Œ
        ç•¶æœ‰æ–°æ•¸æ“šæ™‚è‡ªå‹•æ›´æ–°å…§éƒ¨ç·©è¡å€ã€‚
        """
        thread = threading.Thread(target=self.adam_update_listener, daemon=True)
        thread.start()

    def adam_update_listener(self):
        """
        ç›£è½ ADAM æ›´æ–°äº‹ä»¶ï¼Œè‡ªå‹•æ›´æ–° buffer
        
        æ­¤æ–¹æ³•åœ¨ç¨ç«‹ç·šç¨‹ä¸­é‹è¡Œï¼ŒæŒçºŒç›£è½ADAMæ§åˆ¶å™¨çš„æ•¸æ“šæ›´æ–°äº‹ä»¶ï¼Œ
        ç•¶äº‹ä»¶è¢«è§¸ç™¼æ™‚ï¼Œèª¿ç”¨update_from_adamæ–¹æ³•æ›´æ–°æ•¸æ“šç·©è¡å€ã€‚
        """
        while True:
            self.adam.data_updated_event.wait()  # ç­‰å¾… ADAM è§¸ç™¼äº‹ä»¶
            self.update_from_adam()
            self.adam.data_updated_event.clear()  # æ¸…é™¤äº‹ä»¶

    def update_from_adam(self):
        """
        ç•¶ ADAMScontroller è§¸ç™¼æ›´æ–°æ™‚ï¼Œç›´æ¥æ›´æ–° buffer å…§çš„æ•¸æ“š
        
        å¾ADAMæ§åˆ¶å™¨ç²å–æœ€æ–°çš„ç³»çµ±ç‹€æ…‹æ•¸æ“šï¼ŒåŒ…æ‹¬æº«åº¦å’Œæ§åˆ¶ä¿¡è™Ÿï¼Œ
        ä¸¦å°‡å…¶æ·»åŠ åˆ°æ»‘å‹•çª—å£ç·©è¡å€ä¸­ï¼ŒåŒæ™‚æ›´æ–°æ•¸æ“šè¨ˆæ•¸å™¨ã€‚
        """
        with self.buffer_lock:
            raw_data = np.array([
                self.adam.buffer[0],  # T_GPU
                self.adam.buffer[3],  # T_CDU_out
                self.adam.buffer[2],  # T_CDU_in
                self.adam.buffer[5],  # T_air_in
                self.adam.buffer[6],  # T_air_out
                self.adam.buffer[8],  # fan_duty
                self.adam.buffer[9]   # pump_duty
            ]).reshape(1, -1)
            
            self.buffer = np.roll(self.buffer, -1, axis=0)
            self.buffer[-1, :] = raw_data  # æ›´æ–° buffer
            self.data_count += 1

    def get_window_data(self, normalize=False):
        """
        å–å¾—æ™‚é–“çª—å£æ•¸æ“š
        
        ç²å–ç•¶å‰æ»‘å‹•çª—å£ä¸­çš„æ‰€æœ‰æ•¸æ“šï¼Œå¯é¸æ˜¯å¦é€²è¡Œæ¨™æº–åŒ–è™•ç†ã€‚
        
        Args:
            normalize (bool): è‹¥ç‚º Trueï¼Œå‰‡å›å‚³æ­£è¦åŒ–å¾Œçš„æ•¸æ“š
            
        Returns:
            numpy.ndarray æˆ– torch.Tensor: çª—å£æ•¸æ“šï¼Œå¦‚æœæ•¸æ“šä¸è¶³å‰‡è¿”å›None
            å¦‚æœnormalize=Trueï¼Œè¿”å›æ¨™æº–åŒ–å¾Œçš„å¼µé‡ï¼›å¦å‰‡è¿”å›åŸå§‹numpyæ•¸çµ„
        """
        with self.buffer_lock:
            if self.data_count < self.window_size:
                print(f"â³ ç•¶å‰è³‡æ–™å®¤çª—å…§è³‡æ–™é‡ {self.data_count}/{self.window_size}ï¼Œè«‹ç¨ç­‰...")
                return None
            else:
                print(f"âœ… è³‡æ–™å®¤çª—å…§è³‡æ–™é‡å……è¶³ï¼Œå°‡é–‹å§‹é€²è¡Œé æ¸¬èˆ‡æœ€ä½³åŒ–")
            
            data = self.buffer.copy()
            
            if normalize and hasattr(self.input_scaler, "transform"):
                data = torch.tensor(self.input_scaler.transform(data), dtype=torch.float32).unsqueeze(0).to(self.device)
            return data

    def inverse_transform_predictions(self, scaled_predictions, smooth=True):
        """
        åæ¨™æº–åŒ–é æ¸¬æ•¸æ“šä¸¦å¯é¸æ“‡é€²è¡Œå¹³æ»‘è™•ç†
        
        å°‡æ¨¡å‹è¼¸å‡ºçš„æ¨™æº–åŒ–é æ¸¬çµæœè½‰æ›å›åŸå§‹å°ºåº¦ï¼Œä¸¦å¯é¸æ“‡é€²è¡Œå¹³æ»‘è™•ç†
        ä»¥æ¸›å°‘é æ¸¬çµæœä¸­çš„è·³è®Šã€‚
        
        Args:
            scaled_predictions (numpy.ndarray): æ¨™æº–åŒ–å¾Œçš„é æ¸¬æ•¸æ“š
            smooth (bool): æ˜¯å¦é€²è¡Œå¹³æ»‘è™•ç†ï¼Œé è¨­ç‚ºTrue
            
        Returns:
            numpy.ndarray: åæ¨™æº–åŒ–ï¼ˆä¸¦å¯èƒ½å¹³æ»‘è™•ç†ï¼‰å¾Œçš„é æ¸¬æ•¸æ“š
            
        Raises:
            AttributeError: å¦‚æœoutput_scalerç¼ºå°‘inverse_transformæ–¹æ³•
        """
        if hasattr(self.output_scaler, "inverse_transform"):
            inverse_data = self.output_scaler.inverse_transform(scaled_predictions)[:, 0]
            
            # å¦‚æœéœ€è¦å¹³æ»‘è™•ç†ï¼Œå‰‡èª¿ç”¨å¹³æ»‘å‡½æ•¸
            if smooth:
                final_data = self._smooth_predictions(inverse_data)
            else:
                final_data = inverse_data
            return final_data
        else:
            raise AttributeError("output_scaler ç¼ºå°‘ inverse_transform æ–¹æ³•ï¼Œè«‹æª¢æŸ¥ scaler æ˜¯å¦æ­£ç¢ºè¼‰å…¥ã€‚")

    def transform_input_data(self,data):
        """
        æ¨™æº–åŒ–è¼¸å…¥æ•¸æ“š
        
        å°‡åŸå§‹è¼¸å…¥æ•¸æ“šè½‰æ›ç‚ºæ¨™æº–åŒ–æ ¼å¼ï¼Œä»¥ä¾¿æ¨¡å‹è™•ç†ã€‚
        
        Args:
            data (numpy.ndarray): åŸå§‹è¼¸å…¥æ•¸æ“š
            
        Returns:
            torch.Tensor: æ¨™æº–åŒ–å¾Œçš„æ•¸æ“šå¼µé‡ï¼Œå·²èª¿æ•´ç‚ºæ¨¡å‹æ‰€éœ€çš„ç¶­åº¦å’Œè¨­å‚™
            
        Raises:
            AttributeError: å¦‚æœinput_scalerç¼ºå°‘transformæ–¹æ³•
        """
        if hasattr(self.input_scaler, "transform"):
            return torch.tensor(self.input_scaler.transform(data), dtype=torch.float32).unsqueeze(0).to(self.device)
        else:
            raise AttributeError("input_scaler ç¼ºå°‘ transform æ–¹æ³•ï¼Œè«‹æª¢æŸ¥ scaler æ˜¯å¦æ­£ç¢ºè¼‰å…¥ã€‚")
    
    def _smooth_predictions(self, predictions):
        """
        å¹³æ»‘è™•ç†é æ¸¬æº«åº¦åºåˆ—ï¼Œç‰¹åˆ¥è™•ç†ç¬¬ä¸€å€‹é»çš„è·³è®Šå•é¡Œ
        
        é€šéé™åˆ¶é æ¸¬åºåˆ—ä¸­ç¬¬ä¸€å€‹é»èˆ‡ç•¶å‰å¯¦éš›æº«åº¦çš„å·®å€¼ï¼Œä¸¦ä½¿ç”¨ç·šæ€§æ’å€¼
        å¹³æ»‘è™•ç†å‰å¹¾å€‹é æ¸¬é»ï¼Œæ¸›å°‘é æ¸¬çµæœä¸­çš„ä¸åˆç†è·³è®Šã€‚
        
        Args:
            predictions (numpy.ndarray): åŸå§‹é æ¸¬æº«åº¦åºåˆ—
            
        Returns:
            numpy.ndarray: å¹³æ»‘è™•ç†å¾Œçš„æº«åº¦åºåˆ—
        """
            
        # ç²å–ç•¶å‰å¯¦éš›æº«åº¦
        current_temp = self.adam.buffer[3]  # T_CDU_out çš„ä½ç½®ç´¢å¼•ç‚º 3
        
        # è¨ˆç®—é æ¸¬çš„ç¬¬ä¸€å€‹é»èˆ‡å¯¦éš›æº«åº¦çš„å·®å€¼
        first_point_diff = predictions[0] - current_temp
        
        # åˆ¤æ–·æº«åº¦è®ŠåŒ–è¶¨å‹¢
        if abs(first_point_diff) < 0.05:
            # æº«åº¦è®ŠåŒ–å¾ˆå°ï¼Œè¦–ç‚ºç©©å®š
            self.temp_trend = 0
        elif first_point_diff > 0:
            # æº«åº¦ä¸Šå‡è¶¨å‹¢
            self.temp_trend = 1
        else:
            # æº«åº¦ä¸‹é™è¶¨å‹¢
            self.temp_trend = -1
            
        # æ ¹æ“šè¶¨å‹¢è¨­å®šé–¾å€¼
        if self.temp_trend == 1:
            threshold = 0.1  # ä¸Šå‡è¶¨å‹¢é–¾å€¼
        elif self.temp_trend == -1:
            threshold = 0.1  # ä¸‹é™è¶¨å‹¢é–¾å€¼
        else:
            threshold = 0.05  # ç©©å®šè¶¨å‹¢é–¾å€¼
            
        # è™•ç†ç¬¬ä¸€å€‹é»çš„è·³è®Š
        smoothed_predictions = predictions.copy()
        if abs(first_point_diff) > threshold:
            print(f"âš ï¸ æª¢æ¸¬åˆ°æº«åº¦é æ¸¬è·³è®Š: {first_point_diff:.3f}Â°Cï¼Œé€²è¡Œå¹³æ»‘è™•ç†")
            
            # è¨ˆç®—é™åˆ¶å¾Œçš„ç¬¬ä¸€å€‹é»
            if first_point_diff > 0:
                limited_first_point = current_temp + threshold
            else:
                limited_first_point = current_temp - threshold
                
            # ä½¿ç”¨ç·šæ€§æ’å€¼å¹³æ»‘è™•ç†å‰3å€‹é»
            smooth_range = min(3, len(predictions))
            original_diff = predictions[0] - limited_first_point
            
            for i in range(smooth_range):
                # è¨ˆç®—å¹³æ»‘ä¿‚æ•¸ï¼Œå¾0åˆ°1
                smooth_factor = (i / (smooth_range - 1)) if smooth_range > 1 else 1
                
                # ç·šæ€§æ’å€¼èª¿æ•´
                adjustment = original_diff * smooth_factor
                smoothed_predictions[i] = limited_first_point + adjustment
                
            print(f"ğŸ“Š å¹³æ»‘å‰ç¬¬ä¸€é»: {predictions[0]:.3f}Â°C â†’ å¹³æ»‘å¾Œ: {smoothed_predictions[0]:.3f}Â°C")
        
        return smoothed_predictions